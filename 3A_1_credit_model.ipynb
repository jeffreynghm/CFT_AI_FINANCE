{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YfKOGuX8aAxVU9J5mtmtJaVCOmCX6Hp2","authorship_tag":"ABX9TyOkhwcVV81FubcB81sqozTp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"xNJzQyPTzUXK","executionInfo":{"status":"error","timestamp":1704294324459,"user_tz":-480,"elapsed":638,"user":{"displayName":"Jeffrey TW","userId":"00580688377460210395"}},"outputId":"55550958-c594-4b2d-fa55-90ed279e4e60"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f2c928b10fc7>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mfile_path_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'output_dataset.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mfile_corr_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'corr.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mf_attrib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_attrib_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mattrib_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_attrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/5year.csv'"]}],"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sun Jun 10 18:10:37 2018\n","\n","@author: jeff\n","\n","special thanks to haloboy777 on converting the arff dataset to csv\n","#########################################\n","# Project   : ARFF to CSV converter     #\n","# Created   : 10/01/17 11:08:06         #\n","# Author    : haloboy777                #\n","# Licence   : MIT                       #\n","#########################################\n","\n","\"\"\"\n","\n","'''*************************************\n","1. Import libraries and define key variables\n","'''\n","import os\n","import re\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.metrics import classification_report,roc_curve, auc,confusion_matrix,f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import RFE\n","from sklearn import linear_model,tree\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","import pickle\n","import graphviz\n","\n","'''*************************************\n","1. Define program-wide variables and values\n","'''\n","#set up the working directory where datafiles are all located\n","data_path = os.getcwd()\n","os.chdir(data_path)\n","\n","#read in files\n","file_attrib_in = os.path.join(data_path,'attrib.txt')\n","file_path_in = os.path.join(data_path,'5year.csv')\n","file_path_out = os.path.join(data_path,'output_dataset.txt')\n","file_corr_out = os.path.join(data_path,'corr.txt')\n","f_name = pd.read_csv(file_path_in,sep=',')\n","f_attrib = open(file_attrib_in,\"r\")\n","attrib_str = f_attrib.read()\n","\n","#assign column headers\n","label_name = 'default'\n","re_obj = re.compile(r'X[0-9]+\\s')\n","fields_list = re_obj.split(attrib_str)\n","fields_list = fields_list[1:]\n","fields_list.append(label_name)\n","f_name.columns = fields_list\n","\n","#create X and Y dataset with the right header\n","X = f_name.iloc[:,:-1]\n","Y= f_name.iloc[:,-1]\n","#make sure data types are correct and missing values are handled\n","Y=Y.astype(int)\n","cols = X.columns[X.dtypes.eq(object)]\n","for c in cols:\n","    X[c] = pd.to_numeric(X[c], errors='coerce')\n","X=X.fillna(0)\n","\n","'''\n","2. Define all the functions\n","'''\n","'''\n","##2A. Logistic Regression model\n","'''\n","##2A.i\n","#input the dataframe and the list of columns wanted from it, it return the dataframe with columns selected\n","def select_columns(df, col_list):\n","    df_selected = df[df.columns.intersection(col_list)]\n","    return df_selected\n","\n","##2A.ii\n","#input the support (true/false) of the column lists, and the column header, return the list only with true value\n","def generate_column_lists(col_support,col_list):\n","    i = 0\n","    select_cols = []\n","    len_list = len(col_list)\n","    while i< len_list:\n","        if col_support[i]:\n","            select_cols.append(col_list[i])\n","        i=i+1\n","    return select_cols\n","\n","##2A.iii\n","##try any number of features, return the #of features that deliver the best accuracy (AUC)\n","def optimize_RFE(logreg, X, Y, target_features = 10):\n","    trial_cnt = 1\n","    max_roc_auc=0\n","    #best_feature = 0\n","    best_col_list = []\n","    result_list = {}\n","    col_list = list(X.columns.values)\n","\n","    while trial_cnt<=target_features:\n","        rfe = RFE(logreg,trial_cnt,verbose=1)\n","        rfe = rfe.fit(X,Y)\n","        print(rfe.support_)\n","        print(rfe.ranking_)\n","        col_support = rfe.support_\n","\n","        #select the columns\n","        select_cols = generate_column_lists(col_support, col_list)\n","\n","        #generate the dataframe with only the list of columns\n","        X_selected = select_columns(X,select_cols)\n","        print(list(X_selected.columns))\n","\n","        #build model\n","        print('split data')\n","        X_train, X_test, Y_train, Y_test = train_test_split(X_selected, Y, test_size=0.33, random_state=42)\n","        print('build model')\n","        logreg.fit(X_train,Y_train)\n","        Y_score = logreg.decision_function(X_test)\n","\n","        ##metric 1: roc\n","        fpr, tpr, thresholds = roc_curve(Y_test,Y_score, pos_label=1)\n","        roc_auc = auc(fpr,tpr)\n","\n","        result_list[trial_cnt] = roc_auc\n","        result_list['F_'+str(trial_cnt)] = select_cols\n","\n","        #memorize this setting if this ROC is the highest\n","        if roc_auc > max_roc_auc:\n","            max_roc_auc = roc_auc\n","            #best_feature = trial_cnt\n","            best_col_list = select_cols\n","            print('roc_updated at '+ str(trial_cnt))\n","\n","        trial_cnt=trial_cnt+1\n","\n","    return max_roc_auc, best_col_list, result_list\n","\n","##2A.iv\n","#feed in data to the logistic regression model\n","def train_logreg(X,Y):\n","    print('Logistic Regression')\n","    logreg = linear_model.LogisticRegression(C=1e5)\n","    #find out the features that deliver the highest accuracy\n","    #roc_auc, best_col_list, result_list = optimize_RFE(logreg, X,Y,len(X.columns)-1)\n","\n","    roc_auc, best_col_list, result_list = optimize_RFE(logreg, X,Y,20)\n","\n","    #split the dataset into training set and testing set\n","    X_selected = select_columns(X, best_col_list)\n","    X_train, X_test, Y_train, Y_test = train_test_split(X_selected, Y, test_size=0.33, random_state=42)\n","\n","    #fit the training data to the model\n","    #preprocessing the data\n","    scaler = StandardScaler()\n","    scaler.fit(X_train)\n","    X_train = scaler.transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    logreg.fit(X_train,Y_train)\n","\n","    ##metric 1: roc\n","    Y_score_logreg = logreg.decision_function(X_test)\n","    fpr, tpr, thresholds = roc_curve(Y_test,Y_score_logreg, pos_label=1)\n","    roc_auc = auc(fpr,tpr)\n","    lw=2\n","    plt.figure()\n","    plt.plot(fpr,tpr,color='darkorange',lw=lw,label='ROC curve (area = %0.2f)' %roc_auc)\n","    plt.plot([0,1],[0,1],color='navy',lw=lw,linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic - Logistics Regression Model')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","    ##metric 2: Confusion matrix\n","    Y_pred_logreg = logreg.predict(X_test)\n","    confusion_matrix_logreg = confusion_matrix(Y_test, Y_pred_logreg)\n","    print(confusion_matrix_logreg)\n","    print(classification_report(Y_test, Y_pred_logreg))\n","\n","    #common standard to compare across models\n","    f1_clf = f1_score(Y_test, Y_pred_logreg, average='binary')\n","\n","    ##Quality Check: tets for depedency\n","    corr_m = X_selected.corr()\n","    sns.heatmap(corr_m)\n","    corr_m.to_csv(file_corr_out)\n","    plt.show()\n","\n","    ##save model\n","    f_logreg=open('log_reg.pkl',\"wb+\")\n","    pickle.dump(logreg, f_logreg)\n","    f_logreg.close()\n","\n","    f_logreg_sc = open('logreg_scaler.pkl',\"wb+\")\n","    pickle.dump(scaler, f_logreg_sc)\n","    f_logreg_sc.close()\n","\n","    print('These columns are in the final model')\n","    print(best_col_list)\n","    thefile = open('logreg_cols.txt', 'w+')\n","    for item in best_col_list:\n","        thefile.write(\"%s\\n\" % item)\n","    '''\n","    [[1790   21]\n","    [ 118   22]]\n","             precision    recall  f1-score   support\n","\n","          0       0.94      0.99      0.96      1811\n","          1       0.51      0.16      0.24       140\n","\n","    avg / total       0.91      0.93      0.91      1951\n","    '''\n","    return logreg, f1_clf\n","\n","'''\n","##2B. Decision Tree\n","'''\n","##2B.i\n","#feed in data to the decision tree\n","def train_tree(X,Y):\n","    print('Decision Tree')\n","    #split the dataset into training set and testing set\n","    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.33, random_state=0)\n","\n","    min_leaf_size = int(len(X_train) * 0.01)\n","    tree_clf = tree.DecisionTreeClassifier(min_samples_leaf=min_leaf_size)\n","\n","    #preprocessing the data\n","    scaler = StandardScaler()\n","    scaler.fit(X_train)\n","\n","    X_train = scaler.transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    #fit the training data to the model\n","    tree_clf.fit(X_train,Y_train)\n","\n","    ##metric 1: roc\n","    Y_score_tree = tree_clf.predict(X_test)\n","    fpr, tpr, thresholds = roc_curve(Y_test,Y_score_tree, pos_label=1)\n","    roc_auc = auc(fpr,tpr)\n","    lw=2\n","    plt.figure()\n","    plt.plot(fpr,tpr,color='darkorange',lw=lw,label='ROC curve (area = %0.2f)' %roc_auc)\n","    plt.plot([0,1],[0,1],color='navy',lw=lw,linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic - Decision Tree')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","    ##metric 2: Confusion matrix\n","    Y_pred_tree = tree_clf.predict(X_test)\n","    confusion_matrix_tree = confusion_matrix(Y_test, Y_pred_tree)\n","    print(confusion_matrix_tree)\n","    print(classification_report(Y_test, Y_pred_tree))\n","\n","    #common standard to compare across models\n","    f1_clf = f1_score(Y_test, Y_pred_tree, average='binary')\n","\n","    ##save model\n","    f_tree = open('tree_clf.pkl',\"wb+\")\n","    pickle.dump(tree_clf, f_tree)\n","    f_tree.close()\n","\n","    f_tree_sc = open('tree_scaler.pkl',\"wb+\")\n","    pickle.dump(scaler, f_tree_sc)\n","    f_tree_sc.close()\n","    '''\n","    [[1801   27]\n","    [  62   61]]\n","             precision    recall  f1-score   support\n","\n","          0       0.97      0.99      0.98      1828\n","          1       0.69      0.50      0.58       123\n","\n","    avg / total       0.95      0.95      0.95      1951\n","    '''\n","\n","\n","    return tree_clf,f1_clf\n","\n","##2C Neural Network\n","##2Ci. Grid search that simulate the performance of different neural network design\n","def grid_search(X_train,X_test, Y_train,Y_test,num_training_sample):\n","\n","    best_f1 = 0\n","    best_hidden_layers_list = []\n","    best_hidden_layers_tuple = ()\n","    #various depth\n","    for depth in range(1,5):\n","        print('Depth = '+str(depth))\n","        for layer_size in range(1,8):\n","            neuron_cnt = 0\n","            hidden_layers_list = []\n","            i = 0\n","            while i<depth:\n","                hidden_layers_list.append(layer_size)\n","                neuron_cnt += layer_size\n","                i+=1\n","            #pruning - to avoid over-training\n","            if num_training_sample<neuron_cnt:\n","                break\n","\n","            hidden_layers_tuple = tuple(hidden_layers_list)\n","            nn_clf = MLPClassifier(alpha=1e-5,\n","                     hidden_layer_sizes=hidden_layers_tuple, random_state=1)\n","\n","            nn_clf.fit(X_train,Y_train)\n","            Y_pred = nn_clf.predict(X_test)\n","            temp_f1 = f1_score(Y_test, Y_pred, average='binary')\n","            if temp_f1 > best_f1:\n","                best_f1 = temp_f1\n","                best_hidden_layers_list = hidden_layers_list\n","                best_hidden_layers_tuple = hidden_layers_tuple\n","    print(best_hidden_layers_list)\n","    return best_hidden_layers_list,best_hidden_layers_tuple\n","\n","    #various size\n","# referencing: https://www.springboard.com/blog/beginners-guide-neural-network-in-python-scikit-learn-0-18/\n","##2Cii. train network network\n","def train_NN(X,Y):\n","    print('Neural Network')\n","    #split the dataset into training set and testing set\n","    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.33, random_state=0)\n","\n","    #preprocessing the data\n","    scaler = StandardScaler()\n","    scaler.fit(X_train)\n","    X_train = scaler.transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    num_training_sample = len(X_train)\n","    best_hidden_layers_list,best_hidden_layers_tuple = grid_search(X_train, X_test, Y_train, Y_test,num_training_sample)\n","    nn_clf = MLPClassifier(alpha=1e-5,\n","                     hidden_layer_sizes=best_hidden_layers_tuple, random_state=1)\n","\n","    #fit the training data to the model\n","    nn_clf.fit(X_train,Y_train)\n","\n","    ##metric 1: roc\n","    Y_score_nn = nn_clf.predict(X_test)\n","    fpr, tpr, thresholds = roc_curve(Y_test,Y_score_nn, pos_label=1)\n","    roc_auc = auc(fpr,tpr)\n","    lw=2\n","    plt.figure()\n","    plt.plot(fpr,tpr,color='darkorange',lw=lw,label='ROC curve (area = %0.2f)' %roc_auc)\n","    plt.plot([0,1],[0,1],color='navy',lw=lw,linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic - Neural Network')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","    ##metric 2: Confusion matrix\n","    Y_pred_tree = nn_clf.predict(X_test)\n","    confusion_matrix_tree = confusion_matrix(Y_test, Y_pred_tree)\n","    print(confusion_matrix_tree)\n","    print(classification_report(Y_test, Y_pred_tree))\n","\n","    #common standard to compare across models\n","    f1_clf = f1_score(Y_test, Y_score_nn, average='binary')\n","\n","    ##save model\n","    f_nn = open('nn_clf.pkl',\"wb+\")\n","    pickle.dump(nn_clf, f_nn)\n","    f_nn.close()\n","\n","    f_nn_sc = open('nn_scaler.pkl',\"wb+\")\n","    pickle.dump(scaler, f_nn_sc)\n","    f_nn_sc.close()\n","\n","    '''\n","    [[1808   20]\n","     [  85   38]]\n","                 precision    recall  f1-score   support\n","\n","              0       0.96      0.99      0.97      1828\n","              1       0.66      0.31      0.42       123\n","\n","    avg / total       0.94      0.95      0.94      1951\n","    '''\n","\n","    return nn_clf, f1_clf\n","\n","'''\n","3. Run the functions above\n","'''\n","f1_list = []\n","f1_score_temp= 0\n","#logistic regression model\n","log_reg,f1_score_temp = train_logreg(X,Y)\n","f1_list.append(f1_score_temp)\n","log_reg.get_params()\n","\n","#decision tree\n","tree_clf,f1_score_temp = train_tree(X,Y)\n","f1_list.append(f1_score_temp)\n","tree_clf.get_params()\n","#neural network\n","nn_clf,f1_score_temp = train_NN(X,Y)\n","f1_list.append(f1_score_temp)\n","nn_clf.get_params()\n","\n","'''\n","#4 Visualize the result\n","'''\n","print('********************')\n","print('f1 of the models')\n","print(f1_list)\n","print('********************')\n","\n","#for visualization of decision tree\n","x_feature_name = fields_list[:-1]\n","y_target_name = fields_list[-1]\n","d_tree_out_file = 'decision_tree'\n","dot_data = tree.export_graphviz(tree_clf, out_file=None,\n","                         feature_names=x_feature_name,\n","                         class_names=y_target_name,\n","                         filled=True, rounded=True,\n","                         special_characters=True)\n","graph = graphviz.Source(dot_data)\n","graph.render(d_tree_out_file)"]}]}